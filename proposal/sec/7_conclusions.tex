\vfill
\section{Conclusions}

EchoNet-Dynamic is a video-based deep learning algorithm that achieves state-of-the-art assessment of cardiac function. It uses expert human tracings for weakly supervised learning of left ventricular segmentation and spatiotemporal convolutions on video data to obtain a beat-to-beat cumulative evaluation of the ejection fraction across the entire video. The variance in predictions of EchoNet-Dynamic is comparable to or less than measurements of cardiac function by human experts. EchoNet-Dynamic greatly decreases the labour of the cardiac function assessment by automating the segmentation task and provides the opportunity for more-frequent, rapid evaluations of cardiac function.

Our Project based on EchoNet-Dynamic and did some improvement by Fusion Modeling \& Knowledge Distillation Optimization, We get final dice similarity coefficient Up to 0.9118, with model size down to 196 MB Compare with Original EchoNet-Dynamic model size  311 MB With 0.9206 Dice. We almost get same performance use 59.81\% model size.

We are also contributing to the field of green, low-carbon and environmentally sustainable development by only using one NVIDIA GeForce RTX 4070 Ti GPU to train the segmentation model. Thanks to the reduced model size, the performance requirements for model deployment are lower. 

